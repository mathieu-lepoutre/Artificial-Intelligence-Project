---
title: "Artificial Intelligence Project"
author: "Mathieu Lepoutre"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(keras)
library(tidyverse)
library(caret)
library(tibble)
library(readr)
library(tensorflow)
library(data.table)
library(magrittr)
library(anytime)


```




## Inleiding

De stad Antwerpen kampt met een langdurig probleem dat veel geld en politiemacht opeist. De drugs toevoer is nog nooit zo hoog geweest via de Antwerpse haven. Spijtig genoeg valt dit probleem niet zomaar lossen, het is hetzelfde als dweilen met de kraan open.


Mijn paper gaat over het oplossen van volgend probleem door middel van machine learning. 
Illegale goederen worden binnengesmokkeld via de Antwerpse haven in containers. Een deel van het gigantisch aantal containers dat per jaar binnenkomt wordt doorgestuurd naar scanners. Deze zitten constant op volle capaciteit en halen maar een laag percentage positieve containers eruit.

Wat als we beter kunnen inschatten welke containers positief zullen zijn ?
Via machine learning kunnen we modellen maken die op basis van  data kunnen voorspellen of een container illegale goederen bevat.

Enkele statistieken van de Haven van Antweren;
[Haven van Antwerpen Feiten en Cijfers]https://www.portofantwerp.com/sites/portofantwerp/files/Feiten_en_Cijfers_2019.pdf


```{r }
data <- fread("schipdriecsv.csv")

summary(data)

```




```{r}
data[,AISTrajectPositionTimeStamp:= AISTrajectPositionTimeStamp %>% as.POSIXct]

data[,AISTrajectPositionTimeStamp_num:= AISTrajectPositionTimeStamp %>% as.numeric]
data <- data[AISTrajectPositionTimeStamp %>% order]
data$AISTrajectPositionTimeStamp %>% plot
data <- data[1:200,]
data
count(data)

```
to do; definitie traject

```{r}
mean(data$AISTrajectPositionSpeedOverGround)
```

##Inhoudstafel

# Project analyse:

- Analyse van de probleemstelling
- Scheiden van afhankelijke en onafhankelijke variabelen
- Vastleggen performantie criteria
- Maak beslissingen rond levenscyclus


# Project uitvoering:

- Verzamelen van datasets
- Filteren, opkuisen en samenvoegen
- Randomiseren
- Trainen leeralgoritme
- Instellen hyperparameters
- Validatie
- Testen

  
```{r}
count(data)
```
     

## Model 1: RNN 
### Recurrent Neural Network


** Voor het voorspellen van een tijdseries adhv een recurrent neural network, maak ik gebruik van een Multivariate Time Series Forecasting with LSTMs.

Dit is een veel-tot-één RNN situatie, waar er een sequentie is van gps waarden (tijd, lat, long) van lengte Tx(de hoeveelheid waarden waar in de geschiedenis wordt gekeken om
de volgende waarde te voorspellen). 

Elke deel van de RNN laag zal een gps reading out-putten, en die output wordt gebruikt voor de volgende laag.

```{r}

df.as.Date(df$Date, "%m/%d/%Y %H:%M:%S")
 
str(data)

summary(data)
 
ggplot(data, aes(x=1:nrow(data),y=AISTrajectPositionLongitude)) + geom_line()
ggplot(data, aes(x=1:nrow(data),y=AISTrajectPositionLatitude)) + geom_line()
 
data <- data.matrix(data[,-1])
 
glimpse(data)

ggplot(data[1:100,], aes(x=1:100,y=AISTrajectPositionLongitude)) + geom_line()



```



```{r}

#lookback = 100
#steps =3
#delay = 10


data <- data.matrix(data[,-1])

train_data <- data[1:100,]
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
data <- scale(data, center = mean, scale = std)
```


```{r}

generator <- function(data, lookback, delay, min_index, max_index,
                      shuffle = FALSE, batch_size = 5, step = 6) {
  if (is.null(max_index))
    max_index <- nrow(data) - delay - 1
  i <- min_index + lookback
  function() {
    if (shuffle) {
      rows <- sample(c((min_index+lookback):max_index), size = batch_size)
    } else {
      if (i + batch_size >= max_index)
        i <<- min_index + lookback
      rows <- c(i:min(i+batch_size-1, max_index))
      i <<- i + length(rows)
    }
    
    samples <- array(0, dim = c(length(rows),
                                lookback / step,
                                dim(data)[[-1]]))
    targets <- array(0, dim = c(length(rows)))
    
    for (j in 1:length(rows)) {
      indices <- seq(rows[[j]] - lookback, rows[[j]]-1,
                     length.out = dim(samples)[[2]])
      samples[j,,] <- data[indices,]
      targets[[j]] <- data[rows[[j]] + delay,2]
    }           
    list(samples, targets)
  }
}


```


```{r}
lookback <- 100
step <- 3
delay <- 100
batch_size <- 5


```


```{r}

train_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 1,
  max_index = 100,
  shuffle = TRUE,
  step = step, 
  batch_size = batch_size
)
```


```{r}


val_gen = generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 101,
  max_index = 180,
  step = step,
  batch_size = batch_size
)
```

  
  
```{r}
test_gen <- generator(
  data,
  lookback = lookback,
  delay = delay,
  min_index = 181,
  max_index = NULL,
  step = step,
  batch_size = batch_size
)
```


```{r}

val_steps <- (181 - 101 - lookback) / batch_size
test_steps <- (nrow(data) - 181 - lookback) / batch_size

```


```{r}

model <- keras_model_sequential() %>% 
  layer_flatten(input_shape = c(lookback / step, dim(data)[-1])) %>% 
  layer_dense(units = 32, activation = "relu") %>% 
  layer_dense(units = 1)


```
  
  
```{r}

model %>% compile(
  optimizer = optimizer_rmsprop(),
  loss = "mae"
)

```
  
  
```{r}

history <- model %>% fit_generator(
  train_gen,
  steps_per_epoch = 50,
  epochs = 2,
  validation_data = val_gen,
  validation_steps = val_steps
)

history
```
  
  
         
    ### Machine learning
 
Supervised machine learning
  - regression (linear, polynomial)
  - decision tree
  - Random Forest
  
  
  -KNN : k-Nearest Neighbors
  -Trees :  Classification and Regression Trees
  -Logistic regression
  -Naive-Bayes
  -SVM : Support Vector Machines 
  - LDA Linear Discriminant Analysis
          
          
       
